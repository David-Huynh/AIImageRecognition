{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation and Saving Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 02:33:07.387031: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import data as tf_data\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocess_common import *\n",
    "\n",
    "from record_save_load import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fix some hyperparmeters like IMG_SIZE at a per model level, since each model excels at certain image sizes [1](https://link.springer.com/chapter/10.1007/978-3-030-86340-1_11). \n",
    "\n",
    "We also fix batch size and other parameters due to memory and compute constraints as well. We fix the seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"archive/\"\n",
    "\n",
    "AUTO = tf_data.AUTOTUNE # Parallelize data loading\n",
    "#Hyperparameters\n",
    "BUFFER_SIZE = 1024\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SIZE = 0.2\n",
    "RESIZE_SIZE = (512,512)\n",
    "\n",
    "SEED = 44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CSV's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['Human', 'AI']\n",
    "train_df = pd.read_csv('./archive/train.csv', index_col=0)\n",
    "test_df = pd.read_csv('./archive/test.csv')\n",
    "\n",
    "train_paths = train_df[\"file_name\"].array\n",
    "train_labels = train_df[\"label\"].array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training and Validation Data\n",
    "\n",
    "Here we split the training and validation data based off the class labels to ensure balanced class in the training and validation datasets.\n",
    "\n",
    "Once we split up the data, we use Tensorflows Data pipeline in order to apply our data augmentation(ie. Flipping, rotating, color jitter), and resizing in a parallelized manner. We also set the seed to ensure some level of reproducibility, but because of the way CutMix works setting the seed always resulted in the same cut, so we weren't able to set the seed and it will still give different Cuts with the same images. Instead we provide the augmented dataset for reproducing our results, and in order to compare model performance individually.\n",
    "\n",
    "### Explaining the code\n",
    "\n",
    "Inside `create_datasets()` we duplicate our dataset in order to apply CutMix, we then apply `resize_augment_image` defined in preprocess_common.py which applies the resizing and crops for each model as each model excels at a certain input size [1](https://link.springer.com/chapter/10.1007/978-3-030-86340-1_11). We apply our data augmentation only once in order to reduce computation but it also enhances model invariance and equivariance. We then apply color jitter to improve model robustness to different types of AI images with different color preferences.\n",
    "\n",
    "We found that the models we are using like EfficientNet and ResNet have their own built in preprocessing function for scaling(ie. [0,1] or [-1,1] instead of [0,255]) and normalizing data so we refrain from applying it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 19:53:19.931759: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:906] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.3/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-18 19:53:21.438234: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:906] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.3/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-18 19:53:21.438282: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:906] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.3/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-18 19:53:21.439731: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:906] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.3/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-18 19:53:21.439807: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:906] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.3/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-18 19:53:21.439827: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:906] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.3/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-18 19:53:21.440147: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:906] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.3/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-18 19:53:21.440185: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:906] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.3/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-18 19:53:21.440192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-03-18 19:53:21.440212: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:906] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.3/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-18 19:53:21.440225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21297 MB memory:  -> device: 0, name: AMD Radeon RX 7900 XTX, pci bus id: 0000:00:00.3\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_labels.numpy() if isinstance(train_labels, tf.Tensor) else train_labels\n",
    "\n",
    "# Split the training data into training and validation sets balanced by label\n",
    "(train_paths, val_paths, \n",
    " train_labels, val_labels) = train_test_split(train_paths, \n",
    "                 train_labels, \n",
    "                 test_size=VALIDATION_SIZE, \n",
    "                 stratify=train_labels,\n",
    "                 random_state=SEED)\n",
    " \n",
    "train_labels = keras.ops.one_hot(train_labels,2)\n",
    "val_labels = keras.ops.one_hot(val_labels,2)\n",
    "\n",
    "def create_datasets(train_paths, train_labels, val_paths, val_labels, image_size):\n",
    "    \"\"\" Creates the training and validation datasets for a certain image size.\n",
    "    \n",
    "        Args:\n",
    "            train_paths (list): list of paths to training images\n",
    "            train_labels (list): list of labels for training images\n",
    "            val_paths (list): list of paths to validation images\n",
    "            val_labels (list): list of labels for validation images\n",
    "            image_size (tuple): size to crop the images to\n",
    "        Returns:\n",
    "            (tuple): image tensor and label\n",
    "    \"\"\"\n",
    "    preprocess = Preprocess(RESIZE_SIZE, image_size)\n",
    "    # Shuffles and batches the datasets\n",
    "    train_ds_one = (\n",
    "        tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "        .shuffle(BUFFER_SIZE, seed=SEED * 3)\n",
    "        .map(lambda filename, label: (preprocess.resize_augment_image(PATH+filename, augment=True, c_jitter=True),label), num_parallel_calls=AUTO, deterministic=True)\n",
    "    )\n",
    "    train_ds_two = (\n",
    "        tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "        .shuffle(BUFFER_SIZE, seed=SEED * 2) \n",
    "        .map(lambda filename, label: (preprocess.resize_augment_image(PATH+filename, augment=True, c_jitter=True),label), num_parallel_calls=AUTO, deterministic=True)\n",
    "    )\n",
    "    # Combine the two datasets for CutMix\n",
    "    train_ds = tf_data.Dataset.zip((train_ds_one, train_ds_two))\n",
    "    val_ds = (\n",
    "        tf_data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "        .map(lambda filename, label: (preprocess.resize_augment_image(PATH+filename),label), num_parallel_calls=AUTO, deterministic=True)\n",
    "        .batch(BATCH_SIZE, num_parallel_calls=AUTO, deterministic=True)\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "    return train_ds, val_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying CutMix\n",
    "\n",
    "After applying the initial augmentation and resizing we now apply CutMix to the two training sets to combine them into a single dataset which has been found to improve model robustness and out of distribution performance. [1](https://arxiv.org/abs/1905.04899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dataset(img_size, ram_budget):\n",
    "    \"\"\" Creates the training and validation datasets.\n",
    "    \n",
    "    Args:\n",
    "        img_size (tuple): size to crop the images to\n",
    "        ram_budget (int): RAM budget for autotuning\n",
    "    Returns:\n",
    "        (): dataset\n",
    "    \"\"\"\n",
    "    mixer = Mix(img_size=img_size[0])\n",
    "    train_ds, val_ds = create_datasets(train_paths, train_labels, val_paths, val_labels, img_size)\n",
    "\n",
    "    train_ds_cm = (\n",
    "        train_ds.shuffle(BUFFER_SIZE)\n",
    "        .map(mixer.cutmix, num_parallel_calls=AUTO)\n",
    "        .batch(BATCH_SIZE, num_parallel_calls=AUTO)\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "\n",
    "    options = tf_data.Options()\n",
    "    options.autotune.enabled = True\n",
    "    options.autotune.ram_budget = ram_budget\n",
    "    train_ds_cm = train_ds_cm.with_options(options)\n",
    "    \n",
    "    return train_ds_cm, val_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to TFRecord\n",
    "\n",
    "Here we save our processed data into Tensorflow Records so we have a consistent source of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 19:59:00.975532: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-03-18 19:59:44.873413: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-03-18 20:06:57.929927: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"resnet\": (224,224),\n",
    "    \"efficientnet\": (380,380),\n",
    "    \"swin_transformer\": (256,256)\n",
    "}\n",
    "if not os.path.exists(\"./records\"):\n",
    "    os.makedirs(\"./records\")\n",
    "for model in models:\n",
    "    model_train_ds, val_ds = create_model_dataset(models[model], models[model][0]*models[model][1]*models[model][1]*BATCH_SIZE)\n",
    "    save_to_tfrecord(model_train_ds, f\"records/{model}_train.tfrecord\")\n",
    "    save_to_tfrecord(val_ds, f\"records/{model}_val.tfrecord\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12stad68",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
